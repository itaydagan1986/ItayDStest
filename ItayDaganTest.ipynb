{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "805dac9a",
   "metadata": {},
   "source": [
    "# DS Home Test - Itay Dagan\n",
    "\n",
    "\n",
    "### initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdcace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing relevant libraries for DS regression problem\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the files (press, items, and demand)\n",
    "\n",
    "press=pd.read_csv(\"C:/Users/dagani/OneDrive - HP Inc/Itay General/DS_Test/press.csv\")\n",
    "item=pd.read_csv(\"C:/Users/dagani/OneDrive - HP Inc/Itay General/DS_Test/Item attribute.csv\")\n",
    "demand=pd.read_csv(\"C:/Users/dagani/OneDrive - HP Inc/Itay General/DS_Test/demand_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d510d83",
   "metadata": {},
   "source": [
    "### Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c09447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking % missing data in item file\n",
    "\n",
    "item.isnull().sum()/len(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c32cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "item.Criticality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9660ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#less then 2% missing data for \"Criticality\", i'll fill them with \"A\" based on other data in the set\n",
    "\n",
    "item['Criticality']=item['Criticality'].fillna('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc6f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making sure not other missing values in dataset\n",
    "\n",
    "item.isnull().sum()/len(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08821494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking missing data in item file\n",
    "\n",
    "demand.isnull().sum()/len(demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edfa63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting the few rows where country+region is missing (les then 0.5%)\n",
    "# also deleting empty last unneseccesery column, and rows with 0 orders\n",
    "demand=demand.drop('Unnamed: 5',axis=1)\n",
    "demand=demand.dropna(subset=['Country Name', 'SPO Region'], how='all')\n",
    "demand=demand[demand['Quantity Ordered']>0]\n",
    "len(demand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d43fb7",
   "metadata": {},
   "source": [
    "### Create one unite table with all relevenat fields from the other tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d22d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# almost 10% missing data in importand field, i'll fill it based on the most frequent region for the country\n",
    "# in each row (there are some countries that were belong to diffrent region in the database) \n",
    "df=pd.merge(left=demand,right=item,how='left',on='Item Number')\n",
    "coun_Reg=demand.drop(['Item Number','Order Date','Quantity Ordered'],axis=1)\n",
    "coun_Reg=coun_Reg.groupby(['Country Name']).agg(lambda x:x.value_counts().index[0])\n",
    "coun_Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ade3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new region column to the table, in order to fix wrong region in the db and in order to fill the missing values\n",
    "df=pd.merge(left=df,right=coun_Reg,how='left',on='Country Name')\n",
    "def calc(y,x):\n",
    "    if pd.isna(y):\n",
    "        return x\n",
    "    else:\n",
    "        return y\n",
    "    \n",
    "df['SPO_Region']=df[['SPO Region_y','SPO Region_x']].apply(lambda df: calc(df['SPO Region_y'],df['SPO Region_x']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f7c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update column names and drop unnecessary columns\n",
    "df.rename(columns = {'Item Number':'Item_Number', 'Order Date':'Order_Date','Quantity Ordered':'Quantity_Ordered','purchase or manufacture':'purchase_or_manufacture'}, inplace = True)\n",
    "df=df.drop(['SPO Region_x','SPO Region_y','sub assembly in the press','Country Name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854a50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update date type for order_date, create fields for year+quarter, \n",
    "df['Order_Date']=pd.to_datetime(df.Order_Date)\n",
    "df['Year']=pd.DatetimeIndex(df['Order_Date']).year\n",
    "df['Quarter']=pd.DatetimeIndex(df['Order_Date']).quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1534871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3536cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to add press information (install base per quarter per press) to the main table, this field important for the model\n",
    "press_unpivot=press.melt(id_vars='Press',var_name='Quarter', value_name='amount')\n",
    "press_unpivot.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1440b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create key in the press table (quarter+year+press)\n",
    "press_unpivot['key']=press_unpivot['Quarter']+'_'+press_unpivot['Press']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde76340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create same key in the df (quarter+year+press)\n",
    "def fun_key(y,q,p):   \n",
    "    return 'q'+q+'-'+y[-2:]+'_'+p   \n",
    "\n",
    "df['key']=df[['Year','Quarter','Press']].apply(lambda df: fun_key(str(df['Year']),str(df['Quarter']),df['Press']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge df/press in order to add instal base\n",
    "df=pd.merge(left=df,right=press_unpivot,how='left',on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2461cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organize final fields in the df\n",
    "df=df.drop(['Press_y','key','Quarter_y',],axis=1)\n",
    "df.rename(columns = {'amount':'Install_Base','Quarter_x':'Quarter','Press_x':'Press'}, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f034a1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#give up on filed \"purchase or manu..\", don'n think it relevant, i also group by Q+Y\n",
    "df=df.groupby(['Item_Number','SPO_Region','Year','Quarter','Press','Criticality','Install_Base'])['Quantity_Ordered'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b06949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demand by time graph\n",
    "demand.plot(x='Order Date',y='Quantity Ordered',figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final df\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee6af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#demand.plot.scatter(x='Order Date',y='Quantity Ordered',figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ea3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before making other manipulation on df (coverting string to numbers), load the file with data to forecast\n",
    "toForcast=pd.read_csv(\"C:/Users/dagani/OneDrive - HP Inc/Itay General/DS_Test/toForecast.csv\")\n",
    "dfFull=pd.concat([df,toForcast],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae1094",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFull.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b1767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the labels (string) that need to convert\n",
    "for label, content in dfFull.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "       print (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba519868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first i convert string to categort\n",
    "for label, content in dfFull.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "       dfFull[label]=content.astype(\"category\").cat.as_ordered()\n",
    "\n",
    "dfFull.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1a70f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## turn categorial variable into numbers\n",
    "for label, content in dfFull.items():\n",
    "   if not pd.api.types.is_numeric_dtype(content):\n",
    "        dfFull[label]=pd.Categorical(content).codes\n",
    "dfFull.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427092bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate the 2 db\n",
    "df=dfFull[dfFull['Quantity_Ordered']>0]\n",
    "\n",
    "mf_1 = dfFull['Quarter'] > 2\n",
    "mf_2 = dfFull['Year'] > 2020\n",
    "\n",
    "dfForecast=dfFull.loc[mf_1 & mf_2]\n",
    "\n",
    "dfForecast.info()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66aa8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9854b3d9",
   "metadata": {},
   "source": [
    "# Creating some machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b2604",
   "metadata": {},
   "source": [
    "## Building an evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b5b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create evaluation func\n",
    "#create root mean squered log error between pred and true\n",
    "def rmsle(y_test,test_prediction):\n",
    "    return np.sqrt(mean_absolute_error(y_test,test_prediction))\n",
    "\n",
    "#create func to evaluate model on a few different levels\n",
    "def show_scored(model):\n",
    "    train_preds=model.predict(x_train)\n",
    "    test_prediction=model.predict(x_test)\n",
    "    scores= {\"Training MAE\": mean_absolute_error(y_train,train_preds),\n",
    "             \"Valid MAE\": mean_absolute_error(y_test,test_prediction),\n",
    "             \"Training RMSLE\": rmsle(y_train,train_preds),\n",
    "             \"Valid RMSLE\": rmsle(y_test,test_prediction),\n",
    "             \"Training R^2\": r2_score(y_train,train_preds),\n",
    "             \"Valid R^2\": r2_score(y_test,test_prediction)\n",
    "             }\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d0b92b",
   "metadata": {},
   "source": [
    "## Machine learning - RandomForest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb4916",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# first algo is randomForest, and i sepert the df by periods (old data is for training, new for testing)\n",
    "\n",
    "\n",
    "model=RandomForestRegressor(n_jobs=-1,\n",
    "                           n_estimators=100)\n",
    "\n",
    "df_train=df[df['Year']<2020]\n",
    "df_test=df[df['Year']>2019]\n",
    "\n",
    "x_train,y_train=df_train.drop('Quantity_Ordered',axis=1), df_train.Quantity_Ordered\n",
    "x_test,y_test=df_test.drop('Quantity_Ordered',axis=1), df_test.Quantity_Ordered\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "y_pred=model.predict(x_test)\n",
    "\n",
    "mean_absolute_error(y_pred,y_test)\n",
    "r2_score(y_test,y_pred)\n",
    "\n",
    "show_scored(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2e2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "## very bad results when seperate train/test data by periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ea2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now i'll create the test sample randomize\n",
    "\n",
    "x=df.drop('Quantity_Ordered',axis=1)\n",
    "y=df['Quantity_Ordered']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=27)\n",
    "\n",
    "model=RandomForestRegressor(n_jobs=-1,\n",
    "                           n_estimators=100,\n",
    "                           random_state=28)\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "test_prediction=model.predict(x_test)\n",
    "r2_score(y_test,test_prediction)\n",
    "\n",
    "show_scored(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b336bfd",
   "metadata": {},
   "source": [
    "### Much better score when the test samples are randomize! R^2 of 82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d62b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Quantity_Ordered.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b2ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying some other machine learning model - linear regression \n",
    "\n",
    "x=df.drop('Quantity_Ordered',axis=1)\n",
    "y=df['Quantity_Ordered']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=42)\n",
    "\n",
    "model=LinearRegression()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "test_prediction=model.predict(x_test)\n",
    "mean_absolute_error(y_test,test_prediction)\n",
    "\n",
    "r2_score(y_test,test_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad92686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying some other machine learning model - Ridge model \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,random_state=42)\n",
    "\n",
    "ridge_model=Ridge(alpha=100)\n",
    "ridge_model.fit(x_train,y_train)\n",
    "test_prediction=ridge_model.predict(x_test)\n",
    "MAE=mean_absolute_error(y_test,test_prediction)\n",
    "\n",
    "r2_score(y_test,test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e7847",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with RandomizedSearchCV\n",
    "\n",
    "#### i'll try to imporve the score with randomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Different RandomForestRegressor hyperparameters\n",
    "rf_grid={\"n_estimators\": np.arange(10,100,10),\n",
    "        \"max_depth\": [None,3,5,10],\n",
    "         \"min_samples_split\": np.arange(2,20,2),\n",
    "         \"min_samples_leaf\": np.arange(1,20,2),\n",
    "         \"max_features\": [0.5,1,\"sqrt\",\"auto\"]     \n",
    "        }\n",
    "\n",
    "# Instantiate RandomizedSearchCV\n",
    "rs_model=RandomizedSearchCV(RandomForestRegressor(n_jobs=--1,\n",
    "                                                 random_state=27),\n",
    "                                                 param_distributions=rf_grid,\n",
    "                                                 n_iter=2,\n",
    "                                                 cv=7,\n",
    "                                                 verbose=True)\n",
    "rs_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0968673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best model hyperparameterss\n",
    "rs_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6db50e",
   "metadata": {},
   "source": [
    "x=df.drop('Quantity_Ordered',axis=1)\n",
    "y=df['Quantity_Ordered']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=27)\n",
    "\n",
    "model=RandomForestRegressor(n_jobs=-1,\n",
    "                            n_estimators=5,\n",
    "                            min_samples_split= 12,\n",
    "                            min_samples_leaf= 13,\n",
    "                            max_features= 'auto',\n",
    "                            max_depth= 10,\n",
    "                            random_state=28)\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "test_prediction=model.predict(x_test)\n",
    "r2_score(y_test,test_prediction)\n",
    "\n",
    "show_scored(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9713a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "##testing the model with the new hyperparameterss \n",
    "\n",
    "x=df.drop('Quantity_Ordered',axis=1)\n",
    "y=df['Quantity_Ordered']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=27)\n",
    "\n",
    "model=RandomForestRegressor(n_jobs=-1,\n",
    "                            random_state=27,\n",
    "                            n_estimators=10,\n",
    "                            min_samples_split=16,\n",
    "                            min_samples_leaf=9,\n",
    "                            max_features='auto',\n",
    "                            max_depth= None)\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "test_prediction=model.predict(x_test)\n",
    "r2_score(y_test,test_prediction)\n",
    "\n",
    "show_scored(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e92e5",
   "metadata": {},
   "source": [
    "\n",
    "## Finaly - make prediction for q3-21 & q4-21 data!\n",
    "### I'll train the data on all of the demand set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43f4ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no train/test split now\n",
    "x=df.drop('Quantity_Ordered',axis=1)\n",
    "y=df['Quantity_Ordered']\n",
    "x_test=dfForecast.drop('Quantity_Ordered',axis=1)\n",
    "\n",
    "model=RandomForestRegressor(n_jobs=-1,\n",
    "                           n_estimators=100,\n",
    "                           random_state=28)\n",
    "model.fit(x,y)\n",
    "test_prediction=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fadfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the forecast file\n",
    "toForcast2=pd.read_csv(\"C:/Users/dagani/OneDrive - HP Inc/Itay General/DS_Test/toForecast.csv\")\n",
    "toForcast2['Quantity_Ordered']=test_prediction\n",
    "toForcast2.to_csv(\"ForecastDemandPerReg_Qa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a006adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
